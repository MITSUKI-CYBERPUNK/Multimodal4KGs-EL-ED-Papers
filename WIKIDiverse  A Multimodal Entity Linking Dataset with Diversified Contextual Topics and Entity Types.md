>ACL 2022
# 1 Motivation
- **现有数据集的局限性**：
    - **主题单一**：现有MEL数据集（如社交媒体、影评）仅覆盖少数主题（如5个社交媒体主题），而新闻领域需覆盖体育、政治、灾难等10+主题
    - **实体类型受限**：现有数据集以人物（PER）和组织（ORG）为主，缺乏地点、事件等其他常见类型。
    - **歧义性不足**：通过人工替换实体名称（如姓氏、缩写）构建歧义，真实场景中歧义类型更复杂（如别名、转喻、缩写等），现有数据覆盖不全。
    - **可用性差**：多数数据集未公开，阻碍研究复现与扩展。
- **目标**：构建高质量、多样化、公开的多模态实体链接数据集（WikiDiverse），推动MEL在复杂场景下的研究。

# 2 Contribution
一个名为WikiDiverse的高质量人工标注多模态实体链接（MEL）数据集。该数据集涵盖了多样化的情境主题和实体类型，解决了现有数据集在主题类型、实体类型和提及歧义方面的局限性。数据集包含来自WikiNews的8K图像-标题对，以Wikipedia作为知识库，包含约1600万个实体

# 3 Methodology
## 3.1 **数据集的构建过程与特点**
- **数据来源**：
    - **多模态语料**：从Wikinews采集8K图文对（新闻+配图），覆盖2007-2020年10+主题（体育、政治、灾难等）。
    - **知识库**：基于Wikipedia（含1600万实体），确保实体覆盖广泛。
- **标注流程**：
    1. **实体检测与链接**：标注文本中的提及（mention）并链接至Wikipedia实体。
    2. **质量控制**：双人独立标注+专家审核，Cohen's Kappa一致性达88.98%（实体检测）和83.75%（实体链接）。
    3. **实体类型**：标注7类实体（人物、组织、地点、国家、事件、作品、其他）。
- **核心特点**：
    - **多样性**：覆盖10+主题、7类实体、10种歧义类型（如转喻、别名、缩写）。
    - **难度高**：51.31%的提及与实体名称表面形式不同，44.2%的提及需从10+候选实体中消歧。
    - **多模态对齐**：图文对高度相关（99%的配图与新闻正文强相关）。
    - 
## 3.2 **方法创新：多模态融合与对比学习**
- **两阶段框架**：
    1. **候选检索（CR）**：结合**先验概率（Wikipedia超链接统计）、文本相似度（BM25/BLINK）、视觉相似度（CLIP）筛选Top-K候选**。
    2. **实体消歧（ED）**：通过多模态编码器计算提及与实体的匹配得分。
- **多模态编码器设计**：
    - **文本编码**：**RBET**提取上下文嵌入。
    - **视觉编码**：**ResNet提取网格特征**（替代区域特征，支持端到端训练）。
    - **模态融合**：采用**UNITER（自注意力融合）、LXMERT（跨模态注意力）等结构**，增强图文交互。
- **对比学习优化**：
    - **负样本策略**：结合**困难负例（Top-K候选中的非目标实体）和批内负例（其他提及的目标实体）**。
    - **损失函数**：最大化目标实体与负例的区分度，提升模型鲁棒性。

# 4 Quota
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250215182159.png)
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250215182215.png)
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250215182234.png)

# 5 Q&A
深入了解
其他数据集

# 6 Revelation

