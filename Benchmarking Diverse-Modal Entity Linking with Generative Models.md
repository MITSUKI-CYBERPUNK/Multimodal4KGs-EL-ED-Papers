>ACL 2023
# 1 Motivation
现有的实体链接（Entity Linking, EL）模型通常在单一模态（如纯文本、图像或表格）上表现良好，但在处理多种模态（如文本、图像和表格）的联合任务时，表现不佳
现有方法的局限性：
+ **视觉实体链接**：现有的视觉实体链接方法通常依赖于检索和对比学习，需要存储知识库（KB）中所有实体的密集表示，导致空间复杂性和推理延迟问题。
+ **视觉实体链接**：现有的视觉实体链接方法通常依赖于检索和对比学习，需要存储知识库（KB）中所有实体的密集表示，导致空间复杂性和推理延迟问题。
+ **视觉实体链接**：现有的视觉实体链接方法通常依赖于检索和对比学习，需要存储知识库（KB）中所有实体的密集表示，导致空间复杂性和推理延迟问题。
为了应对这些挑战，作者提出了一个生成式的多模态模型（Generative Diverse-Modal Model, GDMM），该模型能够处理多种模态输入，并通过生成式的方式直接预测实体名称，而不需要存储整个知识库

# 2 Contribution
+ **定义了一个新的多模态实体链接任务（DMEL）** 
	该任务涵盖了文本、图像和表格三种模态的实体链接问题。这个任务的目标是将来自不同模态的实体提及（mention）链接到知识库（KB）中的唯一实体。
+ **构建了一个统一的DMEL基准数据集**
	从现有的五个数据集中构建了一个多模态实体链接的基准数据集，涵盖了文本、图像和表格三种模态。这些数据集包括**GERBIL、WikiDiverse、MELBench、Squall和SLSQL**。这个基准数据集为未来的多模态实体链接研究提供了一个严格的评估平台
+ **提出了一个生成式的多模态模型（GDMM）**
	- 该模型采用**多模态编码器-解码器**结构，能够处理文本、图像和表格等多种模态输入。
	- 该模型通过**自回归**的方式直接生成实体名称，而不需要存储整个知识库的实体表示，从而**减少了空间复杂性和推理延迟**。

# 3 Methodology
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250123183747.png)
## 3.1 输入处理器
![1737629610218.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/1737629610218.png)

## 3.2 GDMM模型架构
### 3.2.1 多模态编码器Encoder
多模态编码器由一个图像编码器、一个文本编码器和一个融合编码器组成
+ 文本编码器和图像编码器使用相同的ViT架构，不同的参数
+ 文本隐藏状态向量{hhLU i}与图像嵌入{hhi V}被投影并连接到一个列表中
+ 一个融合编码器被应用到连接的列表中，它允许在投影的单模态表示之间交叉关注并融合两者
+ 输出是一个隐藏状态的列表{hhMi}。使用预训练的**FLAVA** (Singh等人，2022)参数初始化多模态编码器参数。

### 3.2.2 Decoder
Transformer作为Decoder的基础架构，使用BERT预训练的参数初始化Decoder

### 3.2.3 训练&推理
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250123190647.png)

### 3.2.4 约束解码
当候选集Ci非常大(例如，整个实体空间E)时，自然很难为每个元素计算分数。因此，我们利用约束束搜索**Constrained Beam Search**

## 3.3 预训练GDMM
预训练数据预训练语料库由BLINK (Wu et al.，2020)和维基百科KB中的图像构建。
	BLINK是用于文本实体链接预训练的常用语料库，包括来自维基百科的文档-提及-实体三元组的9M个唯一注释。
	同时，维基百科KB中的图像自然地链接到它们各自的实体名称。
两者合在一起非常适合预训练DMEL模型。除了纯文本BLINK之外，我们还通过链接BLINK和维基图像构建了lv配对的预训练数据。如果实体可以链接到BLINK中的提及，则从维基百科KB收集图像池(维基图像)。

## 3.4 统一学习Unified Learning
在预训练模型上，下游任务的一个直接策略是单任务微调。我们更进一步，研究**统一学习**。具体来说，我们将实行
1. **单任务微调(ST-F)**，它指的是对单个任务的微调;
2. 结合所有数据集的混合训练数据的**多任务微调(multi-task fine-tuning,MT-F)**(rafael et al.， 2022);
3. **使用前缀的多任务微调(MT-FP)**，我们在输入上下文前添加特定于任务的前缀，如“实体链接”和“模式链接”。

# 4 Quota
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250123192201.png)

![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250123192228.png)



所提出的方法有几个缺点。首先，GDMM目前在实体候选集中生成实体名称，但是，我们看到了检索错误如何限制实体链接性能。因此，如何**与检索系统共同工作以减少错误**需要采取适当的行动。其次，**如何处理大型表**仍然有待探索。用表扁平化技术来表示一个庞大的数据库是不可行的。在实践中，可以过滤掉不太可能的候选项来压缩搜索空间，但更有前途的方法是更有效地表示表。
GDMM还可以研究**更多不同模式的任务**。基于所提出的架构，可以很容易地构建新任务，例如视觉问答、接地生成和多模态常识推理。我们相信，随着更多针对不同任务的后续工作的开展，这种方法将成为一个更全面的生成多元模态框架。

# 5 Q&A
Constrained Beam Search
FLAVA
Datasets
Baselines
Pre-Traning Finetune Skills

# 6 Revelation

