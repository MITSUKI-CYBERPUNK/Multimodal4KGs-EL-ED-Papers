>CIKM 2024
# 1 Motivation
1. **现有方法的不足**：
    - 传统多模态实体链接（MEL）方法过度依赖复杂模型架构（如跨模态注意力机制），导致计算成本高、难以扩展。
    - 现有方法未能充分融合视觉语义信息（如忽略图像中的关键线索），且对文本冗余、噪声图像（如无关背景）的鲁棒性较差。
    
2. **多模态消歧的挑战**：
    - 短文本提及（如社交媒体内容）常存在歧义（例如“United States”可能指向国家、运动队或船只），仅依赖文本难以准确链接，需结合视觉上下文辅助决策。
    
3. **大模型的新机遇**：
    - 大型语言模型（LLMs）具备强大的文本理解与推理能力，多模态大模型（MLLMs）可处理图像与文本的联合语义，为高效融合多模态信息提供了新思路。
    - 如何设计轻量化、通用的LLMs框架，仅通过少量参数微调实现高性能MEL，成为亟待解决的问题。
    
4. **任务实际需求**：
    - 知识库中实体描述冗长冗余（如维基百科条目），需生成简洁摘要以提升检索效率；
    - 需要统一的提示模板与流程，解决文本与视觉模态间的语义鸿沟。

作者通过UniMEL框架，旨在克服传统方法的局限性，利用LLMs/MLLMs的生成与推理能力，高效融合多模态信息，实现更精准、低成本的实体链接，同时为多模态知识库构建提供新范式。
# 2 Contribution
+ UniMEL：充分融合图像和上下文的多模态提及，并产生新的简洁描述的实体。这是第一个在MEL任务引入MLLMs为基础的方法。
+ 一个统一的Prompt模板集，专门为多模态实体链接（MEL）任务，有效地弥合模态内容之间的语义差距
# 3 Methodology
大致的优化方向：
+ 对于提及，图像和与提及相关联的上下文信息被处理为MLLM的输入，以便提取图像及其上下文之间更深层次的语义关系。该方法确保了原始图像的完整性被保持（即，而不进行裁剪或编码），从而充分利用未改变的原始数据。
+ 对于实体来说，过于详细和冗余的描述对MEL任务构成了极大的挑战。通过利用LLM的摘要功能，可以获得简短而精确的新描述。
+ 为了缩小候选集，嵌入模型被用来检索和重新排序原始候选集。随后，选择并连接前K个候选者与提及一起生成多项选择查询
+ 为了增强MEL任务中LLM的功能，我们仅微调LLM的一些参数作为选择器来选择提及的引用实体

![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250131121250.png)
UniMEL有四个模块：基于LLMs的实体增强（第3.1节），基于MLMs的提及增强（第3.2节），检索增强（第3.3节），多选择选择（第3.4节）。

## 3.1 实体增强
为了解决实体描述过长和冗余信息的问题，我们使用LLM来有效地总结描述（即生成摘要）。![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250131121545.png)

## 3.2 提及增强
由于MLLM强大的视觉理解和指令遵循能力，我们使用它们来增加伴随图像的提及的描述性信息。![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250131122043.png)

## 3.3 检索增强
计算在矢量化的知识库VE中提及的嵌入的实体和每个实体嵌入的实体之间的余弦相似度，检索具有最高相似度分数的实体。

## 3.4 多选选择
此外，对特定领域的任务和数据进行微调可以增强其处理特定领域任务的能力。在前面几步的高质量数据和小规模候选的支持下，我们设计了一个用于LLM指令调优的提示模板。![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250131122320.png)

# 4 Quota
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250131124245.png)

![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250131124521.png)


# 5 Q&A
LLM
Prompt Finetune
MLLM
参数高效微调（PEFT）

# 6 Revelation
**轻量化设计 + 提示工程 + 高效微调**
