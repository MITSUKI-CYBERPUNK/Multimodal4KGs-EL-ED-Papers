>ACL 2024
# 1 Motivation
1. **解决视觉信息与LLM内部知识之间的鸿沟**：生成式方法难以将**细粒度的视觉模式**（如图像中的物体、场景）与实体知识有效关联。
	LLMs在预训练阶段主要学习文本关联，对视觉输入的泛化能力有限，尤其是对未见过的视觉实体。
2. **结合检索与生成方法的优势**：检索方法能获取相关上下文，生成方法能利用内部知识，但如何有效整合是关键。
3. **处理检索带来的噪声和冲突**：检索结果可能包含不相关信息，需设计机制**区分和优先选择**有效知识。
4. **提升模型对长尾实体的处理能力**：生成式模型对常见实体（头部）表现较好，但对低频实体（尾部）存在偏差，需通过检索补充知识。

# 2 Contribution
5. **提出生成式多模态实体链接框架 GELR**
	- **创新点**：首次将**外部知识检索器**与**生成式大型语言模型（LLM）**结合，通过动态整合内外知识解决多模态实体链接问题。
	- **技术实现**：
	    - **多模态知识检索器**：融合文本描述（通过图像描述工具生成）和细粒度视觉特征（全局及区域级图像特征），提升候选实体召回率。
	    - **优先级调整机制**：根据检索结果与上下文的语义相关性，动态选择依赖外部知识（检索结果）或内部知识（LLM参数）。

6. **噪声感知指令调优（Noise-aware Instruction Tuning）**
	- **问题解决**：针对检索结果中噪声（不相关实体）与LLM内部知识的冲突，提出两种训练目标：
	    - **加权Logits调整**（Eq.5）：通过检索感知（retrieval-aware）与无检索（retrieval-free）输出的差异调整预测分布。
	    - **KL散度约束**（Eq.6）：在检索结果无关时，强制模型输出与无检索结果一致，减少噪声干扰。
	- **优势**：无需显式标注检索结果相关性，模型自动学习知识优先级。

 3. **多模态细粒度检索对齐**
	- **方法创新**：传统检索器（如CLIP）仅对齐整体图像-文本特征，而GELR通过：
	    - **多粒度视觉表征**：结合全局图像特征（ViT提取）和区域特征（RoI裁剪），捕捉细粒度视觉实体（如物体、场景）。
	    - **对齐网络**（Eq.2）：将文本查询、全局图像特征、区域特征投影到统一空间，提升检索精度。

# 3 Methodology
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250125215151.png)

涉及LLM，暂且搁置

# 4 Quota
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250125215256.png)

![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250125215315.png)

![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250125215336.png)

# 5 Q&A
LLM
Environment & Situation
# 6 Revelation

