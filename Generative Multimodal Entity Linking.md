>LREC-COLING 2024
# 1 Motivation
- **文本歧义性增强**：社交媒体中的短文本（如推文、配图说明）通常信息不完整，仅依赖文本难以消歧。  
    _示例_：文本“Harry Potter”可能指向小说、电影或角色，需结合图像（如电影海报）辅助判断。
- **传统方法的低效性**：现有 MEL 方法多采用“检索-重排序”两阶段流程，依赖复杂交互机制（如跨模态注意力），导致计算成本高且难以扩展。

# 2 Contribution
+ **提出首个基于生成式 LLM 的多模态实体链接框架（GEMEL）**
	- **生成式方法创新**：首次将生成式大型语言模型（LLM）引入多模态实体链接（MEL）任务，直接生成实体名称，**摆脱传统“检索-重排序”流程的复杂性**。
	- **跨模态特征对齐**：设计轻量级特征映射层（线性层），将视觉特征投影为 LLM 的“视觉前缀”，实现文本与图像的隐式对齐，**无需微调 LLM 或视觉编码器**。
+ **高效参数微调与性能突破**
	- **参数高效性**：仅训练约 **0.3% 的模型参数**（特征映射层），冻结 LLM（如 LLaMA-7B）和视觉编码器（如 CLIP），显著降低计算成本。
	- **SOTA 性能**：在 WikiDiverse 和 WikiMEL 数据集上分别取得 **7.7%** 和 **8.8%** 的准确率提升，超越现有基于复杂跨模态交互的方法（如 LXMERT、GHMFC）。
	- **可扩展性**：框架兼容任意现成 LLM（如 OPT、Llama 系列），支持未来更大规模模型的即插即用。
+ **缓解 LLM 的尾部实体预测偏差**
	- **发现 LLM 的流行性偏差**：实验表明，LLM（如 GPT-3.5）对常见实体预测准确率高（如 72.0%），但对尾部实体（低频实体）表现差（如 37.5%）。
	- **多模态与上下文学习的联合优化**：通过视觉信息补充文本歧义，并结合相似实例的上下文演示（ICL），显著提升尾部实体准确率（如 **WikiDiverse 尾部实体提升 20%**）。

# 3 Methodology
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250208114307.png)




# 4 Quota
![image.png](https://aquazone.oss-cn-guangzhou.aliyuncs.com/20250208114256.png)


# 5 Q&A
LLM
Datasets

# 6 Revelation
轻量适配 上下文学习
